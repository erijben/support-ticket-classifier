{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Libraries loaded successfully!\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "import emoji\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    classification_report, confusion_matrix\n",
                ")\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.stem import PorterStemmer\n",
                "import nltk\n",
                "import joblib\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Download NLTK data\n",
                "nltk.download('stopwords', quiet=True)\n",
                "print(\"Libraries loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load and Filter Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total records: 2811774\n",
                        "Inbound messages: 1537843\n"
                    ]
                }
            ],
            "source": [
                "# Load dataset\n",
                "df = pd.read_csv('twcs.csv')\n",
                "print(f\"Total records: {len(df)}\")\n",
                "\n",
                "# Filter inbound messages (customer messages only)\n",
                "df = df[df['inbound'] == True].copy()\n",
                "print(f\"Inbound messages: {len(df)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Labeled records: 550586\n",
                        "\n",
                        "Label distribution:\n",
                        "label\n",
                        "Technical    335512\n",
                        "Billing      147847\n",
                        "Account       67227\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Define labeling keywords (will be excluded from features later)\n",
                "LABELING_KEYWORDS = {\n",
                "    'billing': ['bill', 'charge', 'payment', 'invoice', 'refund', 'subscription', \n",
                "                'pay', 'card', 'credit', 'price', 'cost', 'fee', 'receipt', 'paid',\n",
                "                'transaction', 'billing', 'overcharge'],\n",
                "    \n",
                "    'technical': ['error', 'crash', 'bug', 'issue', 'problem', 'broken',\n",
                "                  'slow', 'loading', 'update', 'ios', 'android', 'app', 'website',\n",
                "                  'battery', 'freeze', 'lag', 'download', 'install', 'version',\n",
                "                  'device', 'glitch', 'wifi', 'connection'],\n",
                "    \n",
                "    'account': ['account', 'password', 'login', 'username', 'profile',\n",
                "                'reset', 'verify', 'access', 'locked', 'deactivate', 'email',\n",
                "                'register', 'authentication', 'security', 'settings']\n",
                "}\n",
                "\n",
                "def assign_label(text):\n",
                "    \"\"\"Assign label using keyword-based weak supervision. Returns None for ties.\"\"\"\n",
                "    if pd.isna(text):\n",
                "        return None\n",
                "    \n",
                "    text_lower = text.lower()\n",
                "    \n",
                "    billing_score = sum(1 for kw in LABELING_KEYWORDS['billing'] if kw in text_lower)\n",
                "    technical_score = sum(1 for kw in LABELING_KEYWORDS['technical'] if kw in text_lower)\n",
                "    account_score = sum(1 for kw in LABELING_KEYWORDS['account'] if kw in text_lower)\n",
                "    \n",
                "    scores = [billing_score, technical_score, account_score]\n",
                "    max_score = max(scores)\n",
                "    \n",
                "    # No match or tie -> None\n",
                "    if max_score == 0 or scores.count(max_score) > 1:\n",
                "        return None\n",
                "    \n",
                "    if billing_score == max_score:\n",
                "        return 'Billing'\n",
                "    elif technical_score == max_score:\n",
                "        return 'Technical'\n",
                "    else:\n",
                "        return 'Account'\n",
                "\n",
                "df['label'] = df['text'].apply(assign_label)\n",
                "\n",
                "# Drop rows with no label\n",
                "df = df[df['label'].notna()].copy()\n",
                "print(f\"\\nLabeled records: {len(df)}\")\n",
                "print(f\"\\nLabel distribution:\\n{df['label'].value_counts()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Records after cleaning: 547949\n",
                        "\n",
                        "Example cleaned text:\n",
                        "                                                 text  \\\n",
                        "12  @115714 yâ€™all lie about your â€œgreatâ€ connectio...   \n",
                        "14  @115714 whenever I contact customer support, t...   \n",
                        "16  @Ask_Spectrum Would you like me to email you a...   \n",
                        "\n",
                        "                                           text_clean      label  \n",
                        "12  yall lie great connect bar lte still wont load...  Technical  \n",
                        "14  whenev contact custom support tell shortcod en...    Account  \n",
                        "16  would like email copi one sinc spectrum updat ...    Account  \n"
                    ]
                }
            ],
            "source": [
                "# Initialize tools\n",
                "stop_words = set(stopwords.words('english'))\n",
                "stemmer = PorterStemmer()\n",
                "\n",
                "def clean_text(text):\n",
                "    if pd.isna(text):\n",
                "        return \"\"\n",
                "    \n",
                "    # Convert emojis to text\n",
                "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
                "    \n",
                "    # Remove URLs\n",
                "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
                "    \n",
                "    # Remove mentions and hashtags\n",
                "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
                "    \n",
                "    # Keep only English characters and numbers\n",
                "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
                "    \n",
                "    # Convert to lowercase\n",
                "    text = text.lower().strip()\n",
                "    \n",
                "    # Tokenize, remove stopwords, and stem\n",
                "    tokens = text.split()\n",
                "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words and len(word) > 2]\n",
                "    \n",
                "    # Remove extra whitespace\n",
                "    text = ' '.join(tokens)\n",
                "    \n",
                "    return text\n",
                "\n",
                "df['text_clean'] = df['text'].apply(clean_text)\n",
                "df = df[df['text_clean'].str.len() > 0].copy()\n",
                "print(f\"Records after cleaning: {len(df)}\")\n",
                "print(f\"\\nExample cleaned text:\")\n",
                "print(df[['text', 'text_clean', 'label']].head(3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training:   35020 (70.0%)\n",
                        "Validation: 7480 (15.0%)\n",
                        "Test:       7500 (15.0%)\n"
                    ]
                }
            ],
            "source": [
                "# Use larger sample for better generalization\n",
                "SAMPLE_SIZE = min(50000, len(df))\n",
                "df_sample = df.sample(n=SAMPLE_SIZE, random_state=42)\n",
                "\n",
                "X = df_sample['text_clean']\n",
                "y = df_sample['label']\n",
                "\n",
                "# First split: train+val (85%) vs test (15%)\n",
                "X_temp, X_test, y_temp, y_test = train_test_split(\n",
                "    X, y, test_size=0.15, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "# Second split: train (70% total) vs validation (15% total)\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 * 0.85 â‰ˆ 0.15\n",
                ")\n",
                "\n",
                "print(f\"Training:   {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
                "print(f\"Validation: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
                "print(f\"Test:       {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Excluding 54 labeling keywords from features\n",
                        "Sample excluded keywords: ['profil', 'crash', 'io', 'android', 'download', 'deactiv', 'access', 'instal', 'account', 'error']\n",
                        "\n",
                        "TF-IDF shape: (35020, 5000)\n",
                        "Features extracted: 5000\n"
                    ]
                }
            ],
            "source": [
                "# Flatten all labeling keywords\n",
                "all_labeling_keywords = set()\n",
                "for keywords in LABELING_KEYWORDS.values():\n",
                "    all_labeling_keywords.update([stemmer.stem(kw) for kw in keywords])\n",
                "\n",
                "print(f\"Excluding {len(all_labeling_keywords)} labeling keywords from features\")\n",
                "print(f\"Sample excluded keywords: {list(all_labeling_keywords)[:10]}\")\n",
                "\n",
                "# Custom stop words: English stopwords + labeling keywords\n",
                "custom_stop_words = list(stop_words) + list(all_labeling_keywords)\n",
                "\n",
                "# TF-IDF with bigrams, excluding labeling keywords\n",
                "vectorizer = TfidfVectorizer(\n",
                "    max_features=5000,\n",
                "    ngram_range=(1, 2),\n",
                "    min_df=3,\n",
                "    max_df=0.7,\n",
                "    stop_words=custom_stop_words\n",
                ")\n",
                "\n",
                "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
                "X_val_tfidf = vectorizer.transform(X_val)\n",
                "X_test_tfidf = vectorizer.transform(X_test)\n",
                "\n",
                "print(f\"\\nTF-IDF shape: {X_train_tfidf.shape}\")\n",
                "print(f\"Features extracted: {len(vectorizer.get_feature_names_out())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train Model with Cross-Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training model...\n",
                        "Training complete!\n",
                        "\n",
                        "Running 5-Fold Cross-Validation...\n",
                        "\n",
                        "Cross-Validation F1-Scores: [0.63024553 0.63146852 0.63191395 0.63283399 0.62913145]\n",
                        "Mean CV F1: 0.6311 (+/- 0.0026)\n"
                    ]
                }
            ],
            "source": [
                "# Train model\n",
                "model = LogisticRegression(\n",
                "    max_iter=2000,\n",
                "    solver='lbfgs',\n",
                "    class_weight='balanced',\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "print(\"Training model...\")\n",
                "model.fit(X_train_tfidf, y_train)\n",
                "print(\"Training complete!\")\n",
                "\n",
                "# Cross-validation on training set\n",
                "print(\"\\nRunning 5-Fold Cross-Validation...\")\n",
                "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "cv_scores = cross_val_score(model, X_train_tfidf, y_train, cv=cv, scoring='f1_macro')\n",
                "\n",
                "print(f\"\\nCross-Validation F1-Scores: {cv_scores}\")\n",
                "print(f\"Mean CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Validation Set Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "VALIDATION SET PERFORMANCE\n",
                        "============================================================\n",
                        "Accuracy:  0.6987\n",
                        "Macro F1:  0.6314\n",
                        "\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "     Account       0.35      0.60      0.44       907\n",
                        "     Billing       0.64      0.67      0.66      2012\n",
                        "   Technical       0.87      0.73      0.79      4561\n",
                        "\n",
                        "    accuracy                           0.70      7480\n",
                        "   macro avg       0.62      0.67      0.63      7480\n",
                        "weighted avg       0.74      0.70      0.71      7480\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "y_val_pred = model.predict(X_val_tfidf)\n",
                "\n",
                "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
                "val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"VALIDATION SET PERFORMANCE\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Accuracy:  {val_accuracy:.4f}\")\n",
                "print(f\"Macro F1:  {val_f1:.4f}\")\n",
                "print(\"\\n\" + classification_report(y_val, y_val_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Test Set Evaluation (Final Metrics)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "TEST SET PERFORMANCE (FINAL METRICS)\n",
                        "============================================================\n",
                        "Accuracy:           0.7008\n",
                        "Macro Precision:    0.6238\n",
                        "Macro Recall:       0.6718\n",
                        "Macro F1-Score:     0.6350\n",
                        "\n",
                        "============================================================\n",
                        "CLASSIFICATION REPORT\n",
                        "============================================================\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "     Billing       0.64      0.68      0.66      2017\n",
                        "   Technical       0.87      0.73      0.79      4574\n",
                        "     Account       0.36      0.60      0.45       909\n",
                        "\n",
                        "    accuracy                           0.70      7500\n",
                        "   macro avg       0.62      0.67      0.63      7500\n",
                        "weighted avg       0.75      0.70      0.72      7500\n",
                        "\n",
                        "============================================================\n",
                        "CONFUSION MATRIX\n",
                        "============================================================\n",
                        "[[1380  303  334]\n",
                        " [ 598 3327  649]\n",
                        " [ 175  185  549]]\n",
                        "\n",
                        "Label order: ['Billing', 'Technical', 'Account']\n"
                    ]
                }
            ],
            "source": [
                "y_test_pred = model.predict(X_test_tfidf)\n",
                "\n",
                "# Fixed label order\n",
                "label_order = ['Billing', 'Technical', 'Account']\n",
                "\n",
                "# Metrics\n",
                "accuracy = accuracy_score(y_test, y_test_pred)\n",
                "macro_precision = precision_score(y_test, y_test_pred, average='macro', labels=label_order)\n",
                "macro_recall = recall_score(y_test, y_test_pred, average='macro', labels=label_order)\n",
                "macro_f1 = f1_score(y_test, y_test_pred, average='macro', labels=label_order)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"TEST SET PERFORMANCE (FINAL METRICS)\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Accuracy:           {accuracy:.4f}\")\n",
                "print(f\"Macro Precision:    {macro_precision:.4f}\")\n",
                "print(f\"Macro Recall:       {macro_recall:.4f}\")\n",
                "print(f\"Macro F1-Score:     {macro_f1:.4f}\")\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"CLASSIFICATION REPORT\")\n",
                "print(\"=\"*60)\n",
                "print(classification_report(y_test, y_test_pred, labels=label_order))\n",
                "print(\"=\"*60)\n",
                "print(\"CONFUSION MATRIX\")\n",
                "print(\"=\"*60)\n",
                "print(confusion_matrix(y_test, y_test_pred, labels=label_order))\n",
                "print(f\"\\nLabel order: {label_order}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Export Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ“ Model saved as model.pkl\n",
                        "âœ“ Vectorizer saved as tfidf_vectorizer.pkl\n"
                    ]
                }
            ],
            "source": [
                "# Create pipeline for deployment\n",
                "pipeline = Pipeline([\n",
                "    ('tfidf', vectorizer),\n",
                "    ('clf', model)\n",
                "])\n",
                "\n",
                "joblib.dump(pipeline, 'model.pkl')\n",
                "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
                "print(\"âœ“ Model saved as model.pkl\")\n",
                "print(\"âœ“ Vectorizer saved as tfidf_vectorizer.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Demo: Predict on sample.csv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================================================================\n",
                        "DEMO PREDICTIONS (sample.csv - First 10 rows)\n",
                        "================================================================================\n",
                        "\n",
                        "[1] @AppleSupport causing the reply to be disregarded and the tapped notif...\n",
                        "    â†’ Technical\n",
                        "\n",
                        "[2] @105835 Your business means a lot to us. Please DM your name, zip code...\n",
                        "    â†’ Account\n",
                        "\n",
                        "[3] @76328 I really hope you all change but I'm sure you won't! Because yo...\n",
                        "    â†’ Billing\n",
                        "\n",
                        "[4] @105836 LiveChat is online at the moment - https://t.co/SY94VtU8Kq or ...\n",
                        "    â†’ Account\n",
                        "\n",
                        "[5] @VirginTrains see attached error message. I've tried leaving a voicema...\n",
                        "    â†’ Account\n",
                        "\n",
                        "[6] @105836 Have you tried from another device, Miriam ^MM...\n",
                        "    â†’ Technical\n",
                        "\n",
                        "[7] @VirginTrains yep, I've tried laptop too several times over the past w...\n",
                        "    â†’ Technical\n",
                        "\n",
                        "[8] @105836 It's working OK from here, Miriam. Does this link help https:/...\n",
                        "    â†’ Account\n",
                        "\n",
                        "[9] @VirginTrains I still haven't heard &amp; the number I'm directed to b...\n",
                        "    â†’ Account\n",
                        "\n",
                        "[10] @105836 That's what we're here for Miriam ðŸ˜Š  The team should send you ...\n",
                        "    â†’ Account\n",
                        "\n",
                        "================================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Load sample\n",
                "df_demo = pd.read_csv('sample.csv')\n",
                "df_demo['text_clean'] = df_demo['text'].apply(clean_text)\n",
                "df_demo = df_demo[df_demo['text_clean'].str.len() > 0]\n",
                "\n",
                "# Predict first 10\n",
                "demo_texts = df_demo['text'].head(10).values\n",
                "demo_clean = df_demo['text_clean'].head(10).values\n",
                "demo_tfidf = vectorizer.transform(demo_clean)\n",
                "predictions = model.predict(demo_tfidf)\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(\"DEMO PREDICTIONS (sample.csv - First 10 rows)\")\n",
                "print(\"=\"*80)\n",
                "for i, (text, pred) in enumerate(zip(demo_texts, predictions), 1):\n",
                "    print(f\"\\n[{i}] {text[:70]}...\")\n",
                "    print(f\"    â†’ {pred}\")\n",
                "print(\"\\n\" + \"=\"*80)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
